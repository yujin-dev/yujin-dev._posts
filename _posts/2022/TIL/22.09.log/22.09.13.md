# [INFO] 리눅스 파일 권한 변경
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdKxXah%2Fbtq1jkZjWmO%2F2sWah94UmO18fUdkXzEnM1%2Fimg.png)

> https://recipes4dev.tistory.com/175)

# [INFO][How to load large amount of data from S3 onto Sagemaker](https://repost.aws/questions/QU4m2DyyJQSSCL1QqclXS6ZA/how-to-load-large-amount-of-data-from-s-3-onto-sagemaker)
```
What is the need to load large dataset onto the notebook? If you are pre-processing then there are better ways to do this - Sagemaker Spark processing job, or have your own spark cluster and process or even possibly Glue. If you are exploring the data, you should just use a smaller data set. If you are loading the data for training, Sagemaker supports different modes to read the data and data doesnt have to be downloaded on the notebook.
```
- 대용량 데이터를 분석할 때는 spark 등을 이용하여 처리해서 용량을 줄여서 가져오거나
- training을 돌릴 경우는 적절한 mode를 선택해서 데이터를 가져온다.
 
# [INFO] SageMaker training을 위해 적절한 데이터소스 및 input mode 선택하기
Training 데이터는 데이터 소스와 input mode에 따라 다르게 불러올 수 있다.
 
SageMaker training을 위해 S3, FSx for Lustre, EFS를 통해 로컬 파일 시스템을 사용하는 것처럼 데이터를 로드할 수 있다. S3를 데이터 소스로 사용할 경우 모드는 다음과 같이 있다.
- File Mode : S3에서 데이터를 인스턴스 스토리지(EBS)에 복사한다.
- FastFile Mode : S3를 인스턴스에 POSIX 파일 시스템으로 사용한다.
- Pipe Mode : Unix pipe로 S3에서 인스턴스로 데이터를 스트리밍한다.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/03/ML-2979-image001-new.png)

### S3 File Mode
- 인스턴스 스토리지에 S3에서 데이터를 다운로드한다. 
- 분산 트레이닝을 할 경우 여러 인스턴승에 걸쳐 데이터를 샤드하여 저장할 수 있다.
(200 MB/s)

### S3 FastFile Mode
- S3를 read-only `FUSE`로 POSIX 파일 시스템으로 사용한다. 
- read 작업은 FUSE를 통해 S3에 GET 요청으로 이루어진다. 
- 여러 워커를 사용하면 GB/s 이상도 가능하다.

### S3 Pipe Mode
- FastFile Mode와 유사하다
- S3에서 높은 병렬성과 throughput으로 데이터를 pre-fetch하여 FIFO pipe로 스트리밍한다. 

### FSx for Lustre
- 몇백 GB/s throughput까지 가능하며 높은 IOPS로 확장 가능하다.
- training이 시작되는 순간에 S3에서 FSx for Lustre로 데이터가 복사된다.
- transfer 비용을 줄이기 위해 파일 시스템은 single Availability Zone을 사용한다.
- 비용이 많이 들 수 있고 cold start가 단점

### EFS
- 데이터가 이미 EFS에 있는 경우 가장 적합하다.
- throughput을 bursting throughput, provisioned throughput에서 선택할 수 있다
	- bursting throughput : 150MB/s
	- provisioned throughput : 300 MB/s (12시간)
	
## best practice
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/02/15/ML-2979-image003.png)


> https://aws.amazon.com/ko/blogs/machine-learning/choose-the-best-data-source-for-your-amazon-sagemaker-training-job/
