---
title: "Recommend System Lecture Note(week4)"
category: "recommend"
---
이번 시간의 key word는 다음과 같다.
- Latent Dirichlet Allocation
- Embedding & Word2Vec
- Item2Vec
- Multi-Armed Bandit
 
 (자연어처리에서 들어본 임베딩, Word2Vec을 제외한 나머지는 전혀 처음 들어보는 생소한 단어였다..)


## Latent Dirichlet Allocation을 이용한 추천

 Latent Drichlet Allocation( LDA )는 토픽 모델링 중 하나의 알고리즘이다. 토픽 모델링이란 문서들의 집합에서 토픽을 추출하는 프로세스를 의미한다. 일종의 카테고리를 지칭하는 것 같다. LDA는 주어진 문서와 각 문서가 어떤 토픽을 가지는지 확률 모형으로 풀어낸 과정이다. 나는 문서의 레이블이라 이해하고 어떤 주제를 포함하는지 분류하는 과정으로 이해하였다.

 각 토픽의 단어 분포, 각 문서의 토픽 분포를 Dirichlet 분포로 가정하고 추정한다고 한다. 토픽을 단어들의 분포로 정의하고 어떤 문서에서 단어들이 분포했을 때 각 단어가 갖고 있는 토픽을 분석하는 과정에서 기반이 되는 개념이다. 

 Dirichlet 분포를 통계적으로 표현하면
 [그림]

 예를 들어, 아래와 같은 문서가 있다
 ```
 doc1: 나는 추천을 공부한다.
 doc2: 나는 영화 아이언맨을 봤다.
 doc3: 추천을 통해 영화를 봤다.
 ```

 위 문서에서 토픽 분포를 표현하면
 ```
 doc1: topicA(100%)
 doc2: topicB(100%)
 doc3: topicA(60%), topicB(40%)
 ```
 라고 할 때 각 토픽의 단어 분포를 살피면
 [ chart bar로 표현 ]
 - topic A : 나는/ 추천을 / 공부한다 / 영화를 / 아이언맨을 / 봤다 / 통해
 - topic B : 나는 / 추천을 / 공부한다 / 영화 / 아이언맨을 / 봤다 / 통해 

 LDA의 가정은 문서의 생성이 토픽(들)을 고르고, 선택된 토픽의 확률 분포로부터 단어 하나를 골라 문서에 넣는 과정을 N번 반복하여 N개의 단어를 구성한다는 과정에 있다. 위의 예시에서 토픽으로 A를 골랐다면, topic A의 단어 분포에 따라 단어를 선택하여 문서를 작성하게 된다. 

 LDA가 생성되는 과정은 
 1. 먼저 토픽의 갯수(k)를 정한다. 이 때 k개의 토픽은 모든 문서에 대해 분포되어 있다고 가정한다.  
 2. 문서에 있는 모든 단어를 k개 토픽 중 하나에 랜덤으로 할당한다. 
 3. 각 문서에서 특정 단어(`cat`)를 제외한 나머지 단어들이 토픽이 제대로 할당되어 있다고 가정하고, `cat`에 토픽을 재할당한다. 

예를 들어,  `k=2`로 설정해 토픽A,B가 있다고 하면 A, B 토픽을 처음 각 문서의 모든 단어에 랜덤으로 할당한다.  
```document 1 : apple(A) / banana(B) / cat(?) / dog(A) / cat(B)```
이 때 document1 에서 A에 포함된 확률( P(A|doc1) ) = 2/4이고, 전체 A 중 `cat`이 A일 확률( P(cat|A)) = 1/6라고 한다. 그렇다면 document1의 cat이 A일 확률은 P(A|doc1) * P(cat|A)가 된다. 

그렇다면 LDA를 추천에 어떻게 적용할 수 있을까. 위에서 문서는 유저, 아이템은 단어라고 