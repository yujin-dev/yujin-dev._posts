---
title: "Recommend System Lecture Note(3)"
category: "recommend"
---
3주차 강의의 key word 는 아래와 같다. 
- 모델 기반 협업 필터링
- Latent Factor Model & SVD
- Matrix Factorization
- BPR Optimization with MF
- Annoy

## 3-1. Latent Factor Model & SVD

### Latent Factor Model
Latent Factor Model는 유저와 아이템을 벡터로 압축하여 잠재 요인으로 표현하는 모델이다. 유저와 아이템을 여러 차원의 벡터로 나타내어 각각의 유사도를 확인할 수 있다. 

### Single Value Decomposition(SVD)

Rating Matrix *R*에 대해 유저와 아이템의 어떤 matrix로 분해한다.  
![](https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcb22c772-b4b7-4078-acb1-8761c486a4bc%2FUntitled.png&blockId=a8bfc1be-82df-40f1-814a-53b82ab0611f
)

Truncated SVD는 대표값으로 사용되는 k개의 특이값만 사용한다.    
![](https://www.researchgate.net/publication/323907837/figure/fig2/AS:606612796473344@1521639169497/Schematic-representation-for-singular-value-decomposition-SVD-analysis.png)

하지만 SVD는 분해하는 matrix의 정보가 불완전하면 정의될 수 없기에 entry를 모두 채우는 imputation을 적용한다. 이는 데이터를 왜곡시키고 계산량을 증가시키는 단점이 있다.

## 3-2. Matrix Factorization
MF는 user matrix, item matrix 2개로 이루어진다.  
![](https://miro.medium.com/max/5130/1*b4M7o7W8bfRRxdMxtFoVBQ.png)

참고할 논문 : https://datajobs.com/data-science-repo/Recommender-Systems-%5bNetflix%5d.pdf

### Stochastic Gradient Descent

Rating matrix의 objective는 실제 *R* matrix와 예측치가 최대한 유사하도록 loss를 줄이는 것이다. 학습방식은 stochastic gradient descent에 따라 weight를 업데이트하는 과정에 따른다.   
![](https://miro.medium.com/max/1400/0*1SFw18gXgdSRsa8N)

SVD와 다르게 실측 데이터만을 대상으로 하여 결측치를 채워줄 필요가 없다. 람다를 넣어 L2 정규화를 포함시켜 weight를 조정하여 오버피팅을 방지한다.

SGD에 따라 파라미터를 업데이트한다. 
![](https://i.ibb.co/QCgV5Ys/svd-sgd.png)

#### Biases 추가
![](https://dnddnjs.github.io/assets/img/Untitled-8de4c4ed-58da-42c3-9728-a870d16ec871.png)

유저마다 평점을 매기는 기준이 상대적이기에 편향이 생길 수 있어 전체 평균 및 유저 - 아이템 bias를 추가하여 아래와 같이 파라미터를 업데이트한다.
![](https://i.ibb.co/QCgV5Ys/svd-sgd.png)

참고할 논문: http://yifanhu.net/PUB/cf.pdf

### Alternative Least Square
user / item matrix를 번갈아가며 업데이트한다. P은 고정하여 Q를 업데이트하거나 Q를 고정하여 P를 업데이트하는 방식을 반복한다. 
![](https://i.ibb.co/Csh6Yb0/2021-06-25-10-50-03.png)

Implict Feedback을 처리하는데 있어 Preference를 적용하여 유저가 아이템을 선호하는지 여부를 binary(0 or 1)로 표현하거나 Confidence를 적용하여 유저가 아이템을 얼마나 선호하는지를 `c = 1 + α ⋅ r`로 선형적으로 표현할 수 있다. 

## 3-3. BPR Optimization with MF

선호도가 분명하게 드러나지 않는 Implicit Feedback에서 Ranking을 고려하여 서로 다른 아이템의 선호도를 반영한다. 유저 A가 item i보다 j를 더 선호한다면 이는 유저 A의 personalized ranking으로 이 정보를 MF의 파라미터에 학습에 이용한다. 

Personalized Ranking은 아래 가정에 따르며 관측되지 않은 item에도 정보를 부여하여 학습하며 관측되지 않은 item에 대해서도 ranking이 가능하다는 특징이 있다. 

[ 가정 ]  
- 관측된 item > 관측되지 않은 item 선호
- 관측된 item끼리 선호도 추론 X
- 관측되지 않은 item끼리 선호도 추론 X

BPR 최적화는 최대 사후 확률 추정( Maximum A Posterior )에 따라 파라미터를 추정한다. posterior를 최대화한다는 것은 주어진 유저의 선호도 정보를 최대한 잘 나타내는 파라미터를 추정한다는 의미다. 



참고할 논문 : https://www.google.com/url?sa=D&q=https://arxiv.org/pdf/1205.2618.pdf%3Fsource%3Dpost_page&ust=1626177840000000&usg=AOvVaw3rzSYKQ2yu3JpKyw2piAyt&hl=ko




※ 강의노트는 러닝 스푼즈의 추천시스템 구현하기 수업을 듣고 정리한 내용이다. 